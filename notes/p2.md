![image-20211128152219808](/Users/yunwanxu/Library/Application Support/typora-user-images/image-20211128152219808.png)

本课学习目标：

能够理解word embeddings论文的工作，如google word2vec, GLoVe, Sanjeev Arora's paper



2. Review: Main idea of word2vec

3. Optimization basics

   1. Gradient descent （慢）

   2. Stocastic gradient descent

      神经网络有很多反常识的性质，在凸神经网络当中，SGD的结果可以比单纯的GD又快又好

   3. Stocastic gradients with word vectors

5. Towards GloVe: Count Based vs. direct prediction
6. <img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20211128151022979.png" alt="image-20211128151022979" style="zoom:50%;" />